# Decision Tree and Naive Bayes
Naive Bayes and Decision Tree algorithm implementations from scratch.
Project 1 is presented on the Deep_Learning_Project_1.pdf file and the implementation of the code is presented on DecisionTree&NaiveBayes.ipynb.
Both algorithms are compared on 4 datasets (Experimental.ipnyb).

Datasets:
  - Iris Dataset: https://www.kaggle.com/datasets/uciml/iris
  - Muhsrooms Dataset: https://www.kaggle.com/uciml/mushroom-classification
  - HR Dataset
  - Banknotes Dataset: https://www.kaggle.com/datasets/vivekgediya/banknote-authenticationcsv

# Introduction

In this project, two of the most commonly used classification methods, the Decision Tree and the Naive Bayes algorithms are implemented from scratch. Decision Tree and Naive Bayes methods are classification methods, therefore they can map the given attributes to some output. These classification methods serve for the same purpose, however they differ from each other with the way they make classifications. In machine learning terminology; Decision Tree is defined as a discriminative method while Naive Bayes is stated as a generative method. Both classifiers have their advantages and disadvantages, their success (classifications with high accuracies) depends on the nature of the dataset. Banknote dataset is a series of data that has 4 features (attributes) and a binary output; fake or real. This project is designed to utilize these classifiers to make classification on banknote dataset. Both classification methods trained on the banknote dataset and then resulting accuracies of the models are compared.
